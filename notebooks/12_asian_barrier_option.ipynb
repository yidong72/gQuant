{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 365\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "import cudf\n",
    "cupy.cuda.set_allocator(None)\n",
    "#110.0, 100.0, 120.0, 0.35, 0.1, 0.05\n",
    "N_PATHS = 8192000\n",
    "Y_STEPS = 365 # constant, number of steps per year\n",
    "T = 1.0 # time, unit 1 year\n",
    "K = 110.0 # Strike price\n",
    "B = 100.0 # barrier price\n",
    "S0 = 120.0 # initial stock price \n",
    "sigma = 0.35 # stock annual volatility \n",
    "mu = 0.1 # stock annual return\n",
    "r = 0.05 # stock annual interest rate\n",
    "# calculate total step size\n",
    "N_STEPS = int(np.ceil(T * Y_STEPS))\n",
    "print('steps', N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
    "# randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
    "output =  np.zeros(N_PATHS, dtype=np.float32)\n",
    "\n",
    "doutput =  np.zeros(N_PATHS*6, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # ii - overall thread index\n",
    "    \n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu/Y_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(1.0/Y_STEPS)\n",
    "    running_average = 0.0\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            if n == N_STEPS - 1:\n",
    "                delta_t = T - n/Y_STEPS\n",
    "                tmp1 = delta_t * mu\n",
    "                tmp3 = math.sqrt(delta_t)                \n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            # print(running_average, n, tmp1 * s_curr, sigma,s_curr, tmp3,d_normals[i + n * N_PATHS])\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.4777834415435791 v 18.708305\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9399999999892827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(19.43269 - 19.432878)/2e-4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027397260273972603"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.287468  ,  0.9394655 ,  4.4536147 , ...,  0.67556167,\n",
       "       10.877099  ,  0.52545613], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the differentiation by ADD method\n",
    "\n",
    "The parameters are $T$, $K$, $S_0$, $\\sigma$, $\\mu$, $r$. The option price is computed by \n",
    "$$ p = E(f_i(\\theta)) = \\frac{1}{N}\\sum_i f_i$$\n",
    "where $f_i$ is the option value at the exercise time for the $i^{th}$ path.\n",
    "$$\\nabla_{\\theta} p = \\frac{1}{N}\\sum_i \\nabla_{\\theta} f_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the calculation of gradient of $f_i(\\theta)$. $f_i$ is calculated by Monte Carlo simulation method. Break it down into steps. Without loss of generality, we drop the index $i$ here.\n",
    "\n",
    "$$    \\nabla_{\\theta} f = \n",
    "\\begin{cases}\n",
    "    \\nabla_{\\theta} (a_n(\\theta) - K)  & \\text{if } a_n\\geq K\\\\\n",
    "    (0,0,0,0,0,0)              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where the moving average $a_n$ at step $n$ is\n",
    "\n",
    "$$a_n = g(a_{n-1}, s_{n}) = a_{n-1} + \\frac{s_{n} - a_{n-1}}{n + 1.0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $a_n$:\n",
    "$$ \\nabla_{\\theta} a_n = \\frac{\\partial g} {\\partial a_{n-1}} \\nabla_{\\theta} a_{n-1} + \\frac{\\partial g} {\\partial s_{n}} \\nabla_{\\theta} s_{n} = \\frac{n}{n+1} \\nabla_{\\theta} a_{n-1} + \\frac{1}{n+1} \\nabla_{\\theta} s_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock price $s_n$ at step $n$ is:\n",
    "$$s_n = s(s_{n-1}, \\theta) = s_{n-1} + \\frac{\\mu}{Y} s_{n-1} + \\sigma  \\sqrt{\\frac{1}{Y}} n_n s_{n-1}$$\n",
    "At the last time step $s_n$ is:\n",
    "$$s_n = s(s_{n-1}, \\theta) = s_{n-1} + \\frac{\\mu (T Y - n) }{Y} s_{n-1} + \\sigma  \\sqrt{\\frac{TY-n}{Y}} n_n s_{n-1}$$\n",
    "The gradient of $s_n$:\n",
    "$$\\nabla_{\\theta} s_n = \\nabla_{\\theta} s(s_{n-1}, \\theta) = (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} n_n) \\nabla_{\\theta} s_{n-1} + \\nabla_{\\theta} (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} n_n) s_{n-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial contition $$\\nabla_{\\theta} S_0 = (0,0,1,0,0,0)$$\n",
    "\n",
    "$$\\nabla_{\\theta} (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} v_n) = (0, 0, 0, 1/Y, \\sqrt{1/Y} n_n ,0) $$\n",
    "\n",
    "$$\\nabla_{\\theta} (\\frac{1+ \\mu (T Y - n) }{Y} + \\sigma  \\sqrt{\\frac{TY-n}{Y}} n_n ) = (\\mu + \\frac{1}{2}\\sigma n_n (T-n/Y)^{-\\frac{1}{2}}, 0, 0, (T-n/Y), \\sqrt{T-n/Y} n_n ,0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, doutput, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # ii - overall thread index\n",
    "    \n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu/Y_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(1.0/Y_STEPS)\n",
    "    running_average = 0.0\n",
    "    d_theta = numba.cuda.local.array(6, numba.float64)\n",
    "    d_a = numba.cuda.local.array(6, numba.float64)\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        d_theta[0] = 0 # T\n",
    "        d_theta[1] = 0 # K\n",
    "        d_theta[2] = 1 # S_0\n",
    "        d_theta[3] = 0 # mu\n",
    "        d_theta[4] = 0 # sigma\n",
    "        d_theta[5] = 0 # r\n",
    "        for k in range(6):\n",
    "            d_a[k] = 0\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            if n == N_STEPS - 1:\n",
    "                delta_t = T - n/Y_STEPS\n",
    "                tmp1 = delta_t * mu\n",
    "                tmp3 = math.sqrt(delta_t)  \n",
    "            \n",
    "            ## start to compute the gradient\n",
    "            factor = (1.0+tmp1+sigma*tmp3*d_normals[i + n * N_PATHS])\n",
    "            for k in range(6):\n",
    "                 d_theta[k] *= factor\n",
    "            if n == N_STEPS - 1:\n",
    "                d_theta[0] += (mu + 0.5 * sigma * d_normals[i + n * N_PATHS] / tmp3) * s_curr\n",
    "                d_theta[3] += (T - n/Y_STEPS) * s_curr\n",
    "                d_theta[4] += tmp3 * d_normals[i + n * N_PATHS] * s_curr\n",
    "            else:\n",
    "                d_theta[3] += 1.0/Y_STEPS * s_curr\n",
    "                d_theta[4] += tmp3 * d_normals[i + n * N_PATHS] * s_curr\n",
    "            for k in range(6):\n",
    "                d_a[k] = d_a[k]*n/(n+1.0) + d_theta[k]/(n+1.0)\n",
    "            ## start to compute current stock price and moving average\n",
    "              \n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            # print(running_average, n, tmp1 * s_curr, sigma,s_curr, tmp3,d_normals[i + n * N_PATHS])\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff\n",
    "        # gradient for strik \n",
    "        if running_average > K:\n",
    "            d_a[1] = -1\n",
    "            # adjust gradient for discount factor\n",
    "            for k in range(6):\n",
    "                d_a[k] *= tmp2\n",
    "            d_a[0] += payoff * tmp2* -r \n",
    "            d_a[5] += payoff * tmp2* -T\n",
    "        else:\n",
    "            for k in range(6):\n",
    "                d_a[k] = 0\n",
    "        for k in range(6):\n",
    "            doutput[k*N_PATHS+i] = d_a[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1.8537318706512451 v 18.708305\n",
      "greeks [ -0.9074474  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, doutput, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, doutput, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)\n",
    "greeks = doutput.reshape(6, N_PATHS).mean(axis=1)\n",
    "print('greeks', greeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
    "extern \"C\" __global__ void batched_barrier_option(\n",
    "    float *d_s,\n",
    "    float *d_d,\n",
    "    const float * T,\n",
    "    const float * K,\n",
    "    const float * B,\n",
    "    const float * S0,\n",
    "    const float * sigma,\n",
    "    const float * mu,\n",
    "    const float * r,\n",
    "    const float * d_normals,\n",
    "    const long *N_STEPS,\n",
    "    const long Y_STEPS,\n",
    "    const long N_PATHS,\n",
    "    const long N_BATCH)\n",
    "{\n",
    "  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  unsigned stride = blockDim.x * gridDim.x;\n",
    "  unsigned tid = threadIdx.x;\n",
    "  double d_theta[6];\n",
    "  double d_a[6];\n",
    "\n",
    "  for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
    "  {\n",
    "    d_theta[0] = 0; // T\n",
    "    d_theta[1] = 0; // K\n",
    "    d_theta[2] = 1.0; // S_0\n",
    "    d_theta[3] = 0; // mu\n",
    "    d_theta[4] = 0; // sigma\n",
    "    d_theta[5] = 0; // r\n",
    "    for (unsigned k = 0; k < 6; k++){\n",
    "      d_a[k] = 0.0;\n",
    "    }\n",
    "    \n",
    "    int batch_id = i / N_PATHS;\n",
    "    int path_id = i % N_PATHS;\n",
    "    float s_curr = S0[batch_id];\n",
    "    float tmp1 = mu[batch_id]/Y_STEPS;\n",
    "    float tmp2 = exp(-r[batch_id]*T[batch_id]);\n",
    "    float tmp3 = sqrt(1.0/Y_STEPS);\n",
    "    unsigned n=0;\n",
    "    double running_average = 0.0;\n",
    "    for(unsigned n = 0; n < N_STEPS[batch_id]; n++){\n",
    "        if (n == N_STEPS[batch_id] - 1) {\n",
    "            float delta_t = T[batch_id] - n/Y_STEPS;\n",
    "            tmp1 = delta_t * mu[batch_id];\n",
    "            tmp3 = sqrt(delta_t);\n",
    "        }\n",
    "        float normal = d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
    "        \n",
    "            \n",
    "        // start to compute the gradient\n",
    "        float factor = (1.0+tmp1+sigma[batch_id]*tmp3*normal);\n",
    "        for (unsigned k=0; k < 6; k++) {\n",
    "            d_theta[k] *= factor;\n",
    "        }\n",
    "        \n",
    "        if (n == N_STEPS[batch_id] - 1){\n",
    "                d_theta[0] += (mu[batch_id] + 0.5 * sigma[batch_id] * normal / tmp3) * s_curr;\n",
    "                d_theta[3] += (T[batch_id] - n/Y_STEPS) * s_curr;\n",
    "                d_theta[4] += tmp3 * normal * s_curr;\n",
    "        }\n",
    "        else {\n",
    "                d_theta[3] += 1.0/Y_STEPS * s_curr;\n",
    "                d_theta[4] += tmp3 * normal * s_curr;\n",
    "        }\n",
    "        for (unsigned k = 0; k < 6; k++) {\n",
    "                d_a[k] = d_a[k]*n/(n+1.0) + d_theta[k]/(n+1.0); \n",
    "        }\n",
    "        \n",
    "        \n",
    "        // start to compute current stock price and moving average       \n",
    "       \n",
    "       s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*normal;\n",
    "       running_average += (s_curr - running_average) / (n + 1.0);\n",
    "       if (running_average <= B[batch_id]){\n",
    "           break;\n",
    "       }\n",
    "    }\n",
    "\n",
    "    float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
    "    d_s[i] = tmp2 * payoff;\n",
    "    \n",
    "    // gradient for strik \n",
    "    if (running_average > K[batch_id]){\n",
    "       d_a[1] = -1.0;\n",
    "       // adjust gradient for discount factor\n",
    "       for (unsigned k = 0; k < 6; k++) {\n",
    "            d_a[k] *= tmp2;\n",
    "        }\n",
    "        d_a[0] += payoff * tmp2* -r[batch_id];\n",
    "        d_a[5] += payoff * tmp2* -T[batch_id];\n",
    "        \n",
    "    }\n",
    "    else {\n",
    "        for (unsigned k = 0; k < 6; k++) {\n",
    "           d_a[k] = 0.0;\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    for (unsigned k = 0; k < 6; k++) {\n",
    "       d_d[k*N_PATHS*N_BATCH+i] = d_a[k];\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "''', 'batched_barrier_option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 5, 1, 1, 2, 3, 2, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "cupy.ceil((cupy.random.rand(10)*5)).astype(cupy.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PATHS = 8192000\n",
    "Y_STEPS = 262\n",
    "N_BATCH = 2\n",
    "T = 1.0\n",
    "#110.0, 100.0, 120.0, 0.35, 0.1, 0.05\n",
    "K = cupy.array([110.0, 120.0], dtype=cupy.float32)\n",
    "B = cupy.array([100.0, 90.0], dtype=cupy.float32)\n",
    "S0 = cupy.array([120.0, 100.0], dtype=cupy.float32)\n",
    "sigma = cupy.array([0.35, 0.2], dtype=cupy.float32)\n",
    "mu = cupy.array([0.1, 0.1], dtype=cupy.float32)\n",
    "r =cupy.array([0.05, 0.05], dtype=cupy.float32)\n",
    "T =cupy.array([1.0, 1.1], dtype=cupy.float32)\n",
    "N_STEPS = cupy.ceil(T * Y_STEPS).astype(cupy.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 2.6104929447174072 v [18.756649   1.0737803]\n",
      "(6, 2)\n",
      "gradient [[-8.9926428e-01 -4.6959769e-02]\n",
      " [-6.7189366e-01 -1.3079715e-01]\n",
      " [ 7.7224147e-01  1.6769104e-01]\n",
      " [ 4.8513054e+01  9.8589897e+00]\n",
      " [ 2.0489370e+01  1.5784095e+01]\n",
      " [-1.8756649e+01 -1.1811584e+00]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def batch_run():\n",
    "    number_of_threads = 256\n",
    "    number_of_blocks = (N_PATHS * N_BATCH - 1) // number_of_threads + 1\n",
    "    random_elements = (N_STEPS.max()*N_PATHS*N_BATCH).item()\n",
    "    randoms_gpu = cupy.random.normal(0, 1, random_elements, dtype=cupy.float32)\n",
    "    output = cupy.zeros(N_BATCH*N_PATHS, dtype=cupy.float32)\n",
    "    d_output = cupy.zeros(N_BATCH*N_PATHS*6, dtype=cupy.float32)\n",
    "    cupy.cuda.stream.get_current_stream().synchronize()\n",
    "    s = time.time() \n",
    "    cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n",
    "                       (output, d_output, T, K, B, S0, sigma, mu, r,\n",
    "                        randoms_gpu, N_STEPS, Y_STEPS, N_PATHS, N_BATCH))\n",
    "    v = output.reshape(N_BATCH, N_PATHS).mean(axis=1)\n",
    "    b = d_output.reshape(6, N_BATCH, N_PATHS).mean(axis=2)\n",
    "    cupy.cuda.stream.get_current_stream().synchronize()\n",
    "    e = time.time()\n",
    "    print('time', e-s, 'v',v)\n",
    "    print(b.shape)\n",
    "    print('gradient', b)\n",
    "    return output\n",
    "o = batch_run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.481000000001416"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(18.760712 - 18.71775)/0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-9f78a3372395>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-9f78a3372395>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [ -0.9074474,  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[ -0.9074474,  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
