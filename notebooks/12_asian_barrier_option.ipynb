{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 365\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numba\n",
    "from numba import cuda\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "import cudf\n",
    "cupy.cuda.set_allocator(None)\n",
    "#110.0, 100.0, 120.0, 0.35, 0.1, 0.05\n",
    "N_PATHS = 8192000\n",
    "Y_STEPS = 365 # constant, number of steps per year\n",
    "T = 1.0 # time, unit 1 year\n",
    "K = 110.0 # Strike price\n",
    "B = 100.0 # barrier price\n",
    "S0 = 120.0 # initial stock price \n",
    "sigma = 0.35 # stock annual volatility \n",
    "mu = 0.1 # stock annual return\n",
    "r = 0.05 # stock annual interest rate\n",
    "# calculate total step size\n",
    "N_STEPS = int(np.ceil(T * Y_STEPS))\n",
    "print('steps', N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
    "# randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
    "output =  np.zeros(N_PATHS, dtype=np.float32)\n",
    "\n",
    "doutput =  np.zeros(N_PATHS*6, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # ii - overall thread index\n",
    "    \n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu/Y_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(1.0/Y_STEPS)\n",
    "    running_average = 0.0\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            if n == N_STEPS - 1:\n",
    "                delta_t = T - n/Y_STEPS\n",
    "                tmp1 = delta_t * mu\n",
    "                tmp3 = math.sqrt(delta_t)                \n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            # print(running_average, n, tmp1 * s_curr, sigma,s_curr, tmp3,d_normals[i + n * N_PATHS])\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.448864221572876 v 18.708305\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9399999999892827"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(19.43269 - 19.432878)/2e-4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027397260273972603"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.287468  ,  0.9394655 ,  4.4536147 , ...,  0.67556167,\n",
       "       10.877099  ,  0.52545613], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the differentiation by ADD method\n",
    "\n",
    "The parameters are $T$, $K$, $S_0$, $\\sigma$, $\\mu$, $r$. The option price is computed by \n",
    "$$ p = E(f_i(\\theta)) = \\frac{1}{N}\\sum_i f_i$$\n",
    "where $f_i$ is the option value at the exercise time for the $i^{th}$ path.\n",
    "$$\\nabla_{\\theta} p = \\frac{1}{N}\\sum_i \\nabla_{\\theta} f_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the calculation of gradient of $f_i(\\theta)$. $f_i$ is calculated by Monte Carlo simulation method. Break it down into steps. Without loss of generality, we drop the index $i$ here.\n",
    "\n",
    "$$    \\nabla_{\\theta} f = \n",
    "\\begin{cases}\n",
    "    \\nabla_{\\theta} (a_n(\\theta) - K)  & \\text{if } a_n\\geq K\\\\\n",
    "    (0,0,0,0,0,0)              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where the moving average $a_n$ at step $n$ is\n",
    "\n",
    "$$a_n = g(a_{n-1}, s_{n}) = a_{n-1} + \\frac{s_{n} - a_{n-1}}{n + 1.0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $a_n$:\n",
    "$$ \\nabla_{\\theta} a_n = \\frac{\\partial g} {\\partial a_{n-1}} \\nabla_{\\theta} a_{n-1} + \\frac{\\partial g} {\\partial s_{n}} \\nabla_{\\theta} s_{n} = \\frac{n}{n+1} \\nabla_{\\theta} a_{n-1} + \\frac{1}{n+1} \\nabla_{\\theta} s_{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock price $s_n$ at step $n$ is:\n",
    "$$s_n = s(s_{n-1}, \\theta) = s_{n-1} + \\frac{\\mu}{Y} s_{n-1} + \\sigma  \\sqrt{\\frac{1}{Y}} n_n s_{n-1}$$\n",
    "At the last time step $s_n$ is:\n",
    "$$s_n = s(s_{n-1}, \\theta) = s_{n-1} + \\frac{\\mu (T Y - n) }{Y} s_{n-1} + \\sigma  \\sqrt{\\frac{TY-n}{Y}} n_n s_{n-1}$$\n",
    "The gradient of $s_n$:\n",
    "$$\\nabla_{\\theta} s_n = \\nabla_{\\theta} s(s_{n-1}, \\theta) = (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} n_n) \\nabla_{\\theta} s_{n-1} + \\nabla_{\\theta} (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} n_n) s_{n-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial contition $$\\nabla_{\\theta} S_0 = (0,0,1,0,0,0)$$\n",
    "\n",
    "$$\\nabla_{\\theta} (1 + \\frac{\\mu}{Y} + \\sigma \\sqrt{\\frac{1}{Y}} v_n) = (0, 0, 0, 1/Y, \\sqrt{1/Y} n_n ,0) $$\n",
    "\n",
    "$$\\nabla_{\\theta} (\\frac{1+ \\mu (T Y - n) }{Y} + \\sigma  \\sqrt{\\frac{TY-n}{Y}} n_n ) = (\\mu + \\frac{1}{2}\\sigma n_n (T-n/Y)^{-\\frac{1}{2}}, 0, 0, (T-n/Y), \\sqrt{T-n/Y} n_n ,0) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def numba_gpu_barrier_option(d_s, doutput, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
    "    # ii - overall thread index\n",
    "    \n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "    tmp1 = mu/Y_STEPS\n",
    "    tmp2 = math.exp(-r*T)\n",
    "    tmp3 = math.sqrt(1.0/Y_STEPS)\n",
    "    running_average = 0.0\n",
    "    d_theta = numba.cuda.local.array(6, numba.float64)\n",
    "    d_a = numba.cuda.local.array(6, numba.float64)\n",
    "    for i in range(ii, N_PATHS, stride):\n",
    "        d_theta[0] = 0 # T\n",
    "        d_theta[1] = 0 # K\n",
    "        d_theta[2] = 1 # S_0\n",
    "        d_theta[3] = 0 # mu\n",
    "        d_theta[4] = 0 # sigma\n",
    "        d_theta[5] = 0 # r\n",
    "        for k in range(6):\n",
    "            d_a[k] = 0\n",
    "        s_curr = S0\n",
    "        for n in range(N_STEPS):\n",
    "            if n == N_STEPS - 1:\n",
    "                delta_t = T - n/Y_STEPS\n",
    "                tmp1 = delta_t * mu\n",
    "                tmp3 = math.sqrt(delta_t)  \n",
    "            \n",
    "            ## start to compute the gradient\n",
    "            factor = (1.0+tmp1+sigma*tmp3*d_normals[i + n * N_PATHS])\n",
    "            for k in range(6):\n",
    "                 d_theta[k] *= factor\n",
    "            if n == N_STEPS - 1:\n",
    "                d_theta[0] += (mu + 0.5 * sigma * d_normals[i + n * N_PATHS] / tmp3) * s_curr\n",
    "                d_theta[3] += (T - n/Y_STEPS) * s_curr\n",
    "                d_theta[4] += tmp3 * d_normals[i + n * N_PATHS] * s_curr\n",
    "            else:\n",
    "                d_theta[3] += 1.0/Y_STEPS * s_curr\n",
    "                d_theta[4] += tmp3 * d_normals[i + n * N_PATHS] * s_curr\n",
    "            for k in range(6):\n",
    "                d_a[k] = d_a[k]*n/(n+1.0) + d_theta[k]/(n+1.0)\n",
    "            ## start to compute current stock price and moving average\n",
    "              \n",
    "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
    "            running_average += (s_curr - running_average) / (n + 1.0)\n",
    "            # print(running_average, n, tmp1 * s_curr, sigma,s_curr, tmp3,d_normals[i + n * N_PATHS])\n",
    "            if running_average <= B:\n",
    "                break\n",
    "        payoff = running_average - K if running_average>K else 0\n",
    "        d_s[i] = tmp2 * payoff\n",
    "        # gradient for strik \n",
    "        if running_average > K:\n",
    "            d_a[1] = -1\n",
    "            # adjust gradient for discount factor\n",
    "            for k in range(6):\n",
    "                d_a[k] *= tmp2\n",
    "            d_a[0] += payoff * tmp2* -r \n",
    "            d_a[5] += payoff * tmp2* -T\n",
    "        else:\n",
    "            for k in range(6):\n",
    "                d_a[k] = 0\n",
    "        for k in range(6):\n",
    "            doutput[k*N_PATHS+i] = d_a[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1.846067190170288 v 18.708305\n",
      "greeks [ -0.9074474  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]\n"
     ]
    }
   ],
   "source": [
    "number_of_threads = 256\n",
    "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
    "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, doutput, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "s = time.time()\n",
    "numba_gpu_barrier_option[(number_of_blocks,), (number_of_threads,)](output, doutput, np.float32(T), np.float32(K), \n",
    "                    np.float32(B), np.float32(S0), \n",
    "                    np.float32(sigma), np.float32(mu), \n",
    "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v)\n",
    "greeks = doutput.reshape(6, N_PATHS).mean(axis=1)\n",
    "print('greeks', greeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
    "extern \"C\" __global__ void batched_barrier_option(\n",
    "    float *d_s,\n",
    "    float *d_d,\n",
    "    const float * T,\n",
    "    const float * K,\n",
    "    const float * B,\n",
    "    const float * S0,\n",
    "    const float * sigma,\n",
    "    const float * mu,\n",
    "    const float * r,\n",
    "    const float * d_normals,\n",
    "    const long *N_STEPS,\n",
    "    const long Y_STEPS,\n",
    "    const long N_PATHS,\n",
    "    const long N_BATCH)\n",
    "{\n",
    "  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
    "  unsigned stride = blockDim.x * gridDim.x;\n",
    "  unsigned tid = threadIdx.x;\n",
    "  double d_theta[6];\n",
    "  double d_a[6];\n",
    "\n",
    "  for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
    "  {\n",
    "    d_theta[0] = 0; // T\n",
    "    d_theta[1] = 0; // K\n",
    "    d_theta[2] = 1.0; // S_0\n",
    "    d_theta[3] = 0; // mu\n",
    "    d_theta[4] = 0; // sigma\n",
    "    d_theta[5] = 0; // r\n",
    "    for (unsigned k = 0; k < 6; k++){\n",
    "      d_a[k] = 0.0;\n",
    "    }\n",
    "    \n",
    "    int batch_id = i / N_PATHS;\n",
    "    int path_id = i % N_PATHS;\n",
    "    float s_curr = S0[batch_id];\n",
    "    float tmp1 = mu[batch_id]/Y_STEPS;\n",
    "    float tmp2 = exp(-r[batch_id]*T[batch_id]);\n",
    "    float tmp3 = sqrt(1.0/Y_STEPS);\n",
    "    unsigned n=0;\n",
    "    double running_average = 0.0;\n",
    "    for(unsigned n = 0; n < N_STEPS[batch_id]; n++){\n",
    "        if (n == N_STEPS[batch_id] - 1) {\n",
    "            float delta_t = T[batch_id] - n/Y_STEPS;\n",
    "            tmp1 = delta_t * mu[batch_id];\n",
    "            tmp3 = sqrt(delta_t);\n",
    "        }\n",
    "        float normal = d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
    "        \n",
    "            \n",
    "        // start to compute the gradient\n",
    "        float factor = (1.0+tmp1+sigma[batch_id]*tmp3*normal);\n",
    "        for (unsigned k=0; k < 6; k++) {\n",
    "            d_theta[k] *= factor;\n",
    "        }\n",
    "        \n",
    "        if (n == N_STEPS[batch_id] - 1){\n",
    "                d_theta[0] += (mu[batch_id] + 0.5 * sigma[batch_id] * normal / tmp3) * s_curr;\n",
    "                d_theta[3] += (T[batch_id] - n/Y_STEPS) * s_curr;\n",
    "                d_theta[4] += tmp3 * normal * s_curr;\n",
    "        }\n",
    "        else {\n",
    "                d_theta[3] += 1.0/Y_STEPS * s_curr;\n",
    "                d_theta[4] += tmp3 * normal * s_curr;\n",
    "        }\n",
    "        for (unsigned k = 0; k < 6; k++) {\n",
    "                d_a[k] = d_a[k]*n/(n+1.0) + d_theta[k]/(n+1.0); \n",
    "        }\n",
    "        \n",
    "        \n",
    "        // start to compute current stock price and moving average       \n",
    "       \n",
    "       s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*normal;\n",
    "       running_average += (s_curr - running_average) / (n + 1.0);\n",
    "       if (running_average <= B[batch_id]){\n",
    "           break;\n",
    "       }\n",
    "    }\n",
    "\n",
    "    float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
    "    d_s[i] = tmp2 * payoff;\n",
    "    \n",
    "    // gradient for strik \n",
    "    if (running_average > K[batch_id]){\n",
    "       d_a[1] = -1.0;\n",
    "       // adjust gradient for discount factor\n",
    "       for (unsigned k = 0; k < 6; k++) {\n",
    "            d_a[k] *= tmp2;\n",
    "        }\n",
    "        d_a[0] += payoff * tmp2* -r[batch_id];\n",
    "        d_a[5] += payoff * tmp2* -T[batch_id];\n",
    "        \n",
    "    }\n",
    "    else {\n",
    "        for (unsigned k = 0; k < 6; k++) {\n",
    "           d_a[k] = 0.0;\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    for (unsigned k = 0; k < 6; k++) {\n",
    "       d_d[k*N_PATHS*N_BATCH+i] = d_a[k];\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "''', 'batched_barrier_option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, 4, 4, 1, 3, 3, 1, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "cupy.ceil((cupy.random.rand(10)*5)).astype(cupy.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_STEPS = 252\n",
    "N_BATCH = 2\n",
    "N_PATHS = 102400\n",
    "#110.0, 100.0, 120.0, 0.35, 0.1, 0.05\n",
    "K = cupy.array([110.0, 120.0], dtype=cupy.float32)\n",
    "B = cupy.array([100.0, 90.0], dtype=cupy.float32)\n",
    "S0 = cupy.array([120.0, 100.0], dtype=cupy.float32)\n",
    "sigma = cupy.array([0.35, 0.2], dtype=cupy.float32)\n",
    "mu = cupy.array([0.1, 0.1], dtype=cupy.float32)\n",
    "r =cupy.array([0.05, 0.05], dtype=cupy.float32)\n",
    "T =cupy.array([1.0, 1.1], dtype=cupy.float32)\n",
    "N_STEPS = cupy.ceil(T * Y_STEPS).astype(cupy.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.04647994041442871 v [18.733494   1.0695254]\n",
      "(6, 2)\n",
      "gradient [[-8.9664543e-01 -4.6253104e-02]\n",
      " [-6.7361838e-01 -1.3065936e-01]\n",
      " [ 7.7359498e-01  1.6748641e-01]\n",
      " [ 4.8613876e+01  9.8492012e+00]\n",
      " [ 2.0326763e+01  1.5746067e+01]\n",
      " [-1.8733494e+01 -1.1764779e+00]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def batch_run():\n",
    "    number_of_threads = 256\n",
    "    number_of_blocks = (N_PATHS * N_BATCH - 1) // number_of_threads + 1\n",
    "    random_elements = (N_STEPS.max()*N_PATHS*N_BATCH).item()\n",
    "    randoms_gpu = cupy.random.normal(0, 1, random_elements, dtype=cupy.float32)\n",
    "    output = cupy.zeros(N_BATCH*N_PATHS, dtype=cupy.float32)\n",
    "    d_output = cupy.zeros(N_BATCH*N_PATHS*6, dtype=cupy.float32)\n",
    "    cupy.cuda.stream.get_current_stream().synchronize()\n",
    "    s = time.time() \n",
    "    cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n",
    "                       (output, d_output, T, K, B, S0, sigma, mu, r,\n",
    "                        randoms_gpu, N_STEPS, Y_STEPS, N_PATHS, N_BATCH))\n",
    "    v = output.reshape(N_BATCH, N_PATHS).mean(axis=1)\n",
    "    b = d_output.reshape(6, N_BATCH, N_PATHS).mean(axis=2)\n",
    "    cupy.cuda.stream.get_current_stream().synchronize()\n",
    "    e = time.time()\n",
    "    print('time', e-s, 'v',v)\n",
    "    print(b.shape)\n",
    "    print('gradient', b)\n",
    "    return output\n",
    "o = batch_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterIter(object):\n",
    "    \n",
    "    def __init__(self, batch, K=200.0, S0=200.0, sigma=0.4, mu=0.2, r=0.2, T=2.0, minT=0.1):\n",
    "        self.N_BATCH = batch\n",
    "        self.K = K\n",
    "        self.S0 = S0\n",
    "        self.sigma = sigma\n",
    "        self.mu = mu\n",
    "        self.r = r\n",
    "        self.T = T\n",
    "        self.minT = minT\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def __next__(self):\n",
    "        X = cupy.random.rand(self.N_BATCH, 7, dtype=cupy.float32)\n",
    "        # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
    "        X = X * cupy.array([ 0.99, self.K, self.S0, self.sigma, self.mu, self.r, self.T], dtype=cupy.float32)\n",
    "        # make sure the Barrier is smaller than the Strike price\n",
    "        X[:, 0] = X[:, 0] * X[:, 1]\n",
    "        X[:, 6] += self.minT \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationIter(object):\n",
    "    \n",
    "    def __init__(self, para_iter, N_PATHS=102400, Y_STEPS=252):\n",
    "        self.para_iter = para_iter\n",
    "        self.N_PATHS = N_PATHS\n",
    "        self.Y_STEPS = Y_STEPS\n",
    "        self.N_BATCH = para_iter.N_BATCH\n",
    "        self.block_threads = 256\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        para = next(self.para_iter)\n",
    "        B = para[:, 0]\n",
    "        K = para[:, 1]\n",
    "        S0 = para[:, 2]\n",
    "        sigma = para[:, 3]\n",
    "        mu = para[:, 4]\n",
    "        r = para[:, 5]\n",
    "        T = para[:, 6]\n",
    "        N_STEPS = cupy.ceil(T * self.Y_STEPS).astype(cupy.int64)\n",
    "        number_of_threads = self.block_threads\n",
    "        number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // number_of_threads + 1\n",
    "        random_elements = (N_STEPS.max()*self.N_PATHS*self.N_BATCH).item()\n",
    "        randoms_gpu = cupy.random.normal(0, 1, random_elements, dtype=cupy.float32)\n",
    "        output = cupy.zeros(self.N_BATCH * self.N_PATHS, dtype=cupy.float32)\n",
    "        d_output = cupy.zeros(self.N_BATCH*self.N_PATHS*6, dtype=cupy.float32)\n",
    "        cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n",
    "                                    (output, d_output, T, K, B, S0, sigma, mu, r,\n",
    "                                    randoms_gpu, N_STEPS, self.Y_STEPS, self.N_PATHS, self.N_BATCH))\n",
    "        v = output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)[:,None]\n",
    "        b = d_output.reshape(6, self.N_BATCH, self.N_PATHS).mean(axis=2).T\n",
    "        y = cupy.concatenate([v, b], axis=1)\n",
    "        return para, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ParameterIter(8)\n",
    "sit = SimulationIter(it, N_PATHS=1024000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = next(sit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07311226e+02, -9.38448334e+00, -9.40916002e-01,\n",
       "         9.80268776e-01,  5.16421547e+01,  1.03719924e-02,\n",
       "        -7.39537354e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 1.51883364e-01, -1.03220329e+01, -3.64668272e-03,\n",
       "         2.20857397e-01, -9.22815874e-02,  1.09714583e-01,\n",
       "        -1.11331074e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gquant.dataframe_flow import Node\n",
    "from gquant.dataframe_flow import NodePorts, PortsSpecSchema, TaskSpecSchema\n",
    "from gquant.dataframe_flow import ConfSchema\n",
    "from gquant.dataframe_flow import TaskGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParaNode(Node):\n",
    "\n",
    "    def ports_setup(self):\n",
    "        input_ports = {}\n",
    "        output_ports = {\n",
    "            'para_out': {\n",
    "                PortsSpecSchema.port_type: ParameterIter\n",
    "            },\n",
    "        }\n",
    "        return NodePorts(inports=input_ports, outports=output_ports)\n",
    "\n",
    "    def conf_schema(self):\n",
    "        json = {\n",
    "            \"title\": \"Source node configure\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"batch\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"title\": \"batch size\",\n",
    "                    \"description\": \"the batch size for Asian Barrier Option parameters\",\n",
    "                    \"default\": 16\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        ui = {}\n",
    "        return ConfSchema(json=json, ui=ui)\n",
    "\n",
    "    def init(self):\n",
    "        self.required = {}\n",
    "\n",
    "    def columns_setup(self):\n",
    "        columns_out = {\n",
    "            'para_out': {\n",
    "                'B': 'float32',\n",
    "                'K': 'float32',\n",
    "                \"S0\": \"float32\",\n",
    "                \"sigma\": \"float32\",\n",
    "                \"mu\": \"float32\",\n",
    "                \"r\": \"float32\",\n",
    "                \"T\": \"float32\"\n",
    "            },\n",
    "        }\n",
    "        return columns_out\n",
    "\n",
    "    def process(self, inputs):\n",
    "        output = {}\n",
    "        it = ParameterIter(self.conf.get('batch', 16))\n",
    "        output.update({'para_out': it})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimNode(Node):\n",
    "\n",
    "    def ports_setup(self):\n",
    "        input_ports = {\n",
    "             'para_in': {\n",
    "                PortsSpecSchema.port_type: ParameterIter\n",
    "            },           \n",
    "        }\n",
    "        output_ports = {\n",
    "            'sim_out': {\n",
    "                PortsSpecSchema.port_type: SimulationIter\n",
    "            },\n",
    "        }\n",
    "        return NodePorts(inports=input_ports, outports=output_ports)\n",
    "\n",
    "    def conf_schema(self):\n",
    "        json = {\n",
    "            \"title\": \"Monte Carlo Sim node configure\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"N_PATHS\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"title\": \"Number Paths\",\n",
    "                    \"description\": \"Number of paths in the simulation\",\n",
    "                    \"default\": 102400\n",
    "                },\n",
    "                \"Y_STEPS\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"title\": \"Steps per year\",\n",
    "                    \"description\": \"Number of steps for one year\",\n",
    "                    \"default\": 252\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        ui = {}\n",
    "        return ConfSchema(json=json, ui=ui)\n",
    "\n",
    "    def init(self):\n",
    "        self.required = {}\n",
    "\n",
    "    def columns_setup(self):\n",
    "        self.requried = {\n",
    "            \"para_in\": {\n",
    "                'B': 'float32',\n",
    "                'K': 'float32',\n",
    "                \"S0\": \"float32\",\n",
    "                \"sigma\": \"float32\",\n",
    "                \"mu\": \"float32\",\n",
    "                \"r\": \"float32\",\n",
    "                \"T\": \"float32\"\n",
    "            },\n",
    "        }\n",
    "        columns_out = {\n",
    "            'sim_out': {\n",
    "                'X': 'parameters',\n",
    "                'Y': 'values'\n",
    "            },\n",
    "        }\n",
    "        return columns_out\n",
    "\n",
    "    def process(self, inputs):\n",
    "        it = inputs['para_in']\n",
    "        sit = SimulationIter(it, N_PATHS=self.conf.get('N_PATHS', 102400), Y_STEPS=self.conf.get('Y_STEPS', 252))\n",
    "        output = {}\n",
    "        output.update({'sim_out': sit})\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = 'option_pricing'\n",
    "TaskGraph.register_lab_node(module_name, ParaNode)\n",
    "TaskGraph.register_lab_node(module_name, SimNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5072bed8ab428d9e0b7748c392a9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GQuantWidget(sub=HBox())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taskGraph = TaskGraph()\n",
    "taskGraph.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-79fcc5c09969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaskGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gQuant/gquant/dataframe_flow/taskGraph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "next(taskGraph.run()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-9f78a3372395>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-9f78a3372395>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [ -0.9074474,  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[ -0.9074474,  -0.6714072   0.7713591  48.02249    20.488997  -18.708313 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
